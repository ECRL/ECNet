---
beta_1: 0.6604835948084654
beta_2: 0.24248988924407278
decay: 0.9336387816411169
epochs: 1000
epsilon: 0.4168771003737717
hidden_layers:
- - 34
  - relu
- - 25
  - relu
learning_rate: 0.2538752822891618
output_activation: linear
